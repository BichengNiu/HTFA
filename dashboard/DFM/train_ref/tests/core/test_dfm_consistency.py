# -*- coding: utf-8 -*-
"""
DFMæ¨¡å‹ä¸€è‡´æ€§æµ‹è¯•

å¯¹æ¯” train_ref/core/factor_model.py ä¸ train_model/DynamicFactorModel.py
éªŒè¯è®¡ç®—ç»“æœçš„ä¸€è‡´æ€§
"""

import numpy as np
import pandas as pd
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„ - éœ€è¦å‘ä¸Š6å±‚åˆ°è¾¾HTFAæ ¹ç›®å½•
project_root = Path(__file__).parent.parent.parent.parent.parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æ–°ä»£ç 
from dashboard.DFM.train_ref.core.factor_model import DFMModel, fit_dfm

# å¯¼å…¥è€ä»£ç 
from dashboard.DFM.train_model.DynamicFactorModel import DFM_EMalgo


def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    np.random.seed(42)

    n_time = 100
    n_vars = 10
    n_factors_true = 3

    # ç”ŸæˆçœŸå®å› å­
    true_factors = np.random.randn(n_time, n_factors_true)

    # ç”Ÿæˆè½½è·çŸ©é˜µ
    true_loadings = np.random.randn(n_vars, n_factors_true) * 0.5

    # ç”Ÿæˆè§‚æµ‹æ•°æ®
    observations = true_factors @ true_loadings.T + np.random.randn(n_time, n_vars) * 0.3

    # åˆ›å»ºDataFrame
    dates = pd.date_range('2015-01-01', periods=n_time, freq='M')
    data = pd.DataFrame(
        observations,
        index=dates,
        columns=[f'Var{i+1}' for i in range(n_vars)]
    )

    return data, true_factors, true_loadings


def test_dfm_basic_fit():
    """æµ‹è¯•DFMåŸºæœ¬æ‹Ÿåˆ"""
    print("="*80)
    print("æµ‹è¯•1: DFMåŸºæœ¬æ‹Ÿåˆä¸€è‡´æ€§")
    print("="*80)

    data, true_factors, true_loadings = create_test_data()

    n_factors = 3
    max_lags = 1
    max_iter = 10  # ä½¿ç”¨è¾ƒå°‘è¿­ä»£ä»¥åŠ å¿«æµ‹è¯•

    print(f"\nå‚æ•°è®¾ç½®:")
    print(f"  æ•°æ®å½¢çŠ¶: {data.shape}")
    print(f"  å› å­æ•°é‡: {n_factors}")
    print(f"  æœ€å¤§æ»å: {max_lags}")
    print(f"  æœ€å¤§è¿­ä»£: {max_iter}")

    # æ–°ä»£ç 
    print("\nè¿è¡Œæ–°ä»£ç  (train_ref)...")
    result_new = fit_dfm(
        data=data,
        n_factors=n_factors,
        max_lags=max_lags,
        max_iter=max_iter,
        train_end=None
    )

    print(f"  è¿­ä»£æ¬¡æ•°: {result_new.n_iter}")
    print(f"  æ˜¯å¦æ”¶æ•›: {result_new.converged}")
    print(f"  å¯¹æ•°ä¼¼ç„¶: {result_new.loglikelihood:.4f}")

    # è€ä»£ç 
    print("\nè¿è¡Œè€ä»£ç  (train_model)...")
    result_old = DFM_EMalgo(
        observation=data,
        n_factors=n_factors,
        n_shocks=n_factors,
        n_iter=max_iter,
        train_end_date=None,
        max_lags=max_lags
    )

    # å¯¹æ¯”å› å­
    print("\nå¯¹æ¯”æå–çš„å› å­:")
    factors_new = result_new.factors.values
    factors_old = result_old.x_sm.values

    # å› å­å¯èƒ½æœ‰ç¬¦å·å’Œé¡ºåºå·®å¼‚ï¼Œéœ€è¦æ‰¾åˆ°æœ€ä½³å¯¹é½
    corr_matrix = np.corrcoef(factors_new.T, factors_old.T)[:n_factors, n_factors:]
    abs_corr = np.abs(corr_matrix)

    print(f"  å› å­ç›¸å…³ç³»æ•°çŸ©é˜µ:")
    print(f"  {abs_corr}")

    mean_corr = np.mean(np.max(abs_corr, axis=1))
    print(f"  å¹³å‡æœ€å¤§ç›¸å…³ç³»æ•°: {mean_corr:.4f}")

    # å¯¹æ¯”è½½è·çŸ©é˜µ
    print("\nå¯¹æ¯”è½½è·çŸ©é˜µ:")
    loadings_new = result_new.loadings
    loadings_old = result_old.Lambda

    # è®¡ç®—è½½è·çš„FrobeniusèŒƒæ•°å·®å¼‚ï¼ˆå½’ä¸€åŒ–ï¼‰
    loadings_new_norm = loadings_new / np.linalg.norm(loadings_new, axis=0, keepdims=True)
    loadings_old_norm = loadings_old / np.linalg.norm(loadings_old, axis=0, keepdims=True)

    # è€ƒè™‘ç¬¦å·å·®å¼‚
    min_diff = np.inf
    for signs in [1, -1]:
        diff = np.linalg.norm(loadings_new_norm - signs * loadings_old_norm, 'fro')
        min_diff = min(min_diff, diff)

    print(f"  å½’ä¸€åŒ–FrobeniusèŒƒæ•°å·®å¼‚: {min_diff:.6f}")

    # å¯¹æ¯”å¯¹æ•°ä¼¼ç„¶ï¼ˆè€ä»£ç å¯èƒ½æ²¡æœ‰æ­¤å±æ€§ï¼‰
    print("\nå¯¹æ¯”å¯¹æ•°ä¼¼ç„¶:")
    loglik_new = result_new.loglikelihood
    print(f"  æ–°ä»£ç : {loglik_new:.4f}")

    loglik_match = True
    if hasattr(result_old, 'loglik'):
        loglik_old = result_old.loglik
        print(f"  è€ä»£ç : {loglik_old:.4f}")
        print(f"  ç›¸å¯¹å·®å¼‚: {abs(loglik_new - loglik_old) / abs(loglik_old):.6f}")
        loglik_match = abs(loglik_new - loglik_old) / abs(loglik_old) < 0.1
    else:
        print(f"  è€ä»£ç : æœªæä¾›ï¼ˆå¯¹è±¡æ²¡æœ‰loglikå±æ€§ï¼‰")

    # åˆ¤æ–­é€šè¿‡æ ‡å‡†
    passed = (mean_corr > 0.95 and  # å› å­é«˜åº¦ç›¸å…³
              min_diff < 0.5 and     # è½½è·ç›¸ä¼¼
              loglik_match)           # ä¼¼ç„¶æ¥è¿‘ï¼ˆå¦‚æœå¯æ¯”ï¼‰

    print(f"\n{'âœ“ æµ‹è¯•é€šè¿‡' if passed else 'âœ— æµ‹è¯•å¤±è´¥'}")
    print(f"  (æ ‡å‡†: å› å­ç›¸å…³>0.95, è½½è·å·®å¼‚<0.5, ä¼¼ç„¶ç›¸å¯¹å·®å¼‚<10%)")

    return passed


def test_dfm_with_train_split():
    """æµ‹è¯•å¸¦è®­ç»ƒæœŸåˆ‡åˆ†çš„DFM"""
    print("\n" + "="*80)
    print("æµ‹è¯•2: å¸¦è®­ç»ƒæœŸåˆ‡åˆ†çš„DFMæ‹Ÿåˆ")
    print("="*80)

    data, _, _ = create_test_data()

    n_factors = 2
    train_end = data.index[70]  # 70%è®­ç»ƒï¼Œ30%æµ‹è¯•

    print(f"\nå‚æ•°è®¾ç½®:")
    print(f"  è®­ç»ƒæœŸç»“æŸ: {train_end}")
    print(f"  è®­ç»ƒæ ·æœ¬: 70, å…¨æ ·æœ¬: {len(data)}")

    # æ–°ä»£ç 
    print("\nè¿è¡Œæ–°ä»£ç ...")
    result_new = fit_dfm(
        data=data,
        n_factors=n_factors,
        max_lags=1,
        max_iter=15,
        train_end=str(train_end.date())
    )

    # è€ä»£ç 
    print("è¿è¡Œè€ä»£ç ...")
    result_old = DFM_EMalgo(
        observation=data,
        n_factors=n_factors,
        n_shocks=n_factors,
        n_iter=15,
        train_end_date=str(train_end.date()),
        max_lags=1
    )

    # å¯¹æ¯”å› å­ï¼ˆç¡®ä¿æ—¶é—´ç»´åº¦ä¸€è‡´ï¼‰
    factors_new = result_new.factors.values  # (n_time_new, n_factors)
    factors_old = result_old.x_sm.values     # (n_time_old, n_factors)

    # åªæ¯”è¾ƒå…±åŒçš„æ—¶é—´èŒƒå›´
    n_time_common = min(factors_new.shape[0], factors_old.shape[0])
    factors_new_common = factors_new[:n_time_common, :]
    factors_old_common = factors_old[:n_time_common, :]

    # è®¡ç®—ç›¸å…³æ€§
    corr_matrix = np.corrcoef(factors_new_common.T, factors_old_common.T)[:n_factors, n_factors:]
    mean_corr = np.mean(np.abs(np.max(np.abs(corr_matrix), axis=1)))

    print(f"\nå¯¹æ¯”å› å­æ•°é‡: {factors_new.shape[0]} vs {factors_old.shape[0]}")
    print(f"å…±åŒæ—¶é—´èŒƒå›´: {n_time_common} ä¸ªæ ·æœ¬")

    print(f"\nå› å­ç›¸å…³æ€§: {mean_corr:.4f}")

    # å¯¹æ¯”ä¼¼ç„¶
    print(f"\nå¯¹æ•°ä¼¼ç„¶:")
    print(f"  æ–°ä»£ç : {result_new.loglikelihood:.4f}")
    if hasattr(result_old, 'loglik'):
        print(f"  è€ä»£ç : {result_old.loglik:.4f}")
    else:
        print(f"  è€ä»£ç : æœªæä¾›")

    passed = mean_corr > 0.90

    print(f"\n{'âœ“ æµ‹è¯•é€šè¿‡' if passed else 'âœ— æµ‹è¯•å¤±è´¥'} (ç›¸å…³æ€§>0.90)")

    return passed


def test_dfm_convergence():
    """æµ‹è¯•DFMæ”¶æ•›è¡Œä¸º"""
    print("\n" + "="*80)
    print("æµ‹è¯•3: DFMæ”¶æ•›è¡Œä¸º")
    print("="*80)

    data, _, _ = create_test_data()

    n_factors = 3
    max_iter = 30

    print(f"\næµ‹è¯•æ”¶æ•›æ€§...")

    # æ–°ä»£ç 
    result_new = fit_dfm(
        data=data,
        n_factors=n_factors,
        max_lags=1,
        max_iter=max_iter
    )

    # è€ä»£ç 
    result_old = DFM_EMalgo(
        observation=data,
        n_factors=n_factors,
        n_shocks=n_factors,
        n_iter=max_iter,
        max_lags=1
    )

    print(f"\næ–°ä»£ç :")
    print(f"  è¿­ä»£æ¬¡æ•°: {result_new.n_iter}")
    print(f"  æ˜¯å¦æ”¶æ•›: {result_new.converged}")
    print(f"  æœ€ç»ˆä¼¼ç„¶: {result_new.loglikelihood:.4f}")

    print(f"\nè€ä»£ç :")
    print(f"  è¿­ä»£æ¬¡æ•°: {max_iter}")
    if hasattr(result_old, 'loglik'):
        print(f"  æœ€ç»ˆä¼¼ç„¶: {result_old.loglik:.4f}")
    else:
        print(f"  æœ€ç»ˆä¼¼ç„¶: æœªæä¾›")

    # æ£€æŸ¥æ–°ä»£ç æ˜¯å¦æ­£ç¡®è¯†åˆ«æ”¶æ•›
    passed = result_new.converged or result_new.n_iter == max_iter

    print(f"\n{'âœ“ æµ‹è¯•é€šè¿‡' if passed else 'âœ— æµ‹è¯•å¤±è´¥'}")

    return passed


def test_dfm_dimensions():
    """æµ‹è¯•ä¸åŒç»´åº¦é…ç½®"""
    print("\n" + "="*80)
    print("æµ‹è¯•4: ä¸åŒç»´åº¦é…ç½®")
    print("="*80)

    data, _, _ = create_test_data()

    test_configs = [
        (2, 1),  # 2å› å­, 1æ»å
        (4, 1),  # 4å› å­, 1æ»å
        (3, 2),  # 3å› å­, 2æ»å
    ]

    all_passed = True

    for n_factors, max_lags in test_configs:
        print(f"\næµ‹è¯•é…ç½®: k={n_factors}, lags={max_lags}")

        try:
            result_new = fit_dfm(
                data=data,
                n_factors=n_factors,
                max_lags=max_lags,
                max_iter=10
            )

            result_old = DFM_EMalgo(
                observation=data,
                n_factors=n_factors,
                n_shocks=n_factors,
                n_iter=10,
                max_lags=max_lags
            )

            # æ£€æŸ¥å½¢çŠ¶
            assert result_new.factors.shape == (len(data), n_factors)
            assert result_new.loadings.shape == (data.shape[1], n_factors)

            print(f"  âœ“ å½¢çŠ¶æ­£ç¡®")

            # æ£€æŸ¥ç›¸å…³æ€§
            corr = np.corrcoef(
                result_new.factors.values.T,
                result_old.x_sm.values.T
            )[:n_factors, n_factors:]

            mean_corr = np.mean(np.abs(np.max(np.abs(corr), axis=1)))
            print(f"  å› å­ç›¸å…³æ€§: {mean_corr:.4f}")

            if mean_corr < 0.85:
                all_passed = False
                print(f"  âœ— ç›¸å…³æ€§ä¸è¶³")

        except Exception as e:
            print(f"  âœ— å¤±è´¥: {e}")
            all_passed = False

    print(f"\n{'âœ“ æ‰€æœ‰é…ç½®é€šè¿‡' if all_passed else 'âœ— éƒ¨åˆ†é…ç½®å¤±è´¥'}")

    return all_passed


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*80)
    print("DFMæ¨¡å‹ä¸€è‡´æ€§æµ‹è¯•å¥—ä»¶")
    print("å¯¹æ¯” train_ref vs train_model")
    print("="*80)

    results = []

    try:
        results.append(("åŸºæœ¬æ‹Ÿåˆ", test_dfm_basic_fit()))
    except Exception as e:
        print(f"\nâœ— åŸºæœ¬æ‹Ÿåˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        results.append(("åŸºæœ¬æ‹Ÿåˆ", False))

    try:
        results.append(("è®­ç»ƒæœŸåˆ‡åˆ†", test_dfm_with_train_split()))
    except Exception as e:
        print(f"\nâœ— è®­ç»ƒæœŸåˆ‡åˆ†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        results.append(("è®­ç»ƒæœŸåˆ‡åˆ†", False))

    try:
        results.append(("æ”¶æ•›è¡Œä¸º", test_dfm_convergence()))
    except Exception as e:
        print(f"\nâœ— æ”¶æ•›è¡Œä¸ºæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        results.append(("æ”¶æ•›è¡Œä¸º", False))

    try:
        results.append(("å¤šç»´åº¦é…ç½®", test_dfm_dimensions()))
    except Exception as e:
        print(f"\nâœ— å¤šç»´åº¦é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        results.append(("å¤šç»´åº¦é…ç½®", False))

    # æ€»ç»“
    print("\n" + "="*80)
    print("æµ‹è¯•æ€»ç»“")
    print("="*80)

    for name, passed in results:
        status = "âœ“ é€šè¿‡" if passed else "âœ— å¤±è´¥"
        print(f"  {name}: {status}")

    total_passed = sum(1 for _, passed in results if passed)
    total_tests = len(results)

    print(f"\næ€»è®¡: {total_passed}/{total_tests} æµ‹è¯•é€šè¿‡")

    if total_passed == total_tests:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼train_ref DFMæ¨¡å‹ä¸è€ä»£ç ä¸€è‡´ã€‚")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å·®å¼‚ã€‚")
        return 1


if __name__ == "__main__":
    exit(main())
