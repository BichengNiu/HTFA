# -*- coding: utf-8 -*-
"""
é¢†å…ˆæ»ååˆ†æç»„ä»¶
æä¾›å¤šå˜é‡é¢†å…ˆæ»åç­›é€‰åˆ†æåŠŸèƒ½ï¼ŒåŒ…å«ç›¸å…³æ€§å’ŒKLæ•£åº¦åŒé‡è¯„ä¼°
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import logging
from typing import List, Dict, Any, Optional, Tuple

# é…ç½®matplotlibä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

from dashboard.ui.components.analysis.timeseries.base import TimeSeriesAnalysisComponent
from dashboard.explore import perform_combined_lead_lag_analysis, get_detailed_lag_data_for_candidate
from dashboard.explore.preprocessing.frequency_alignment import align_series_for_analysis
from dashboard.explore.preprocessing.standardization import standardize_series

logger = logging.getLogger(__name__)


class LeadLagAnalysisComponent(TimeSeriesAnalysisComponent):
    """é¢†å…ˆæ»ååˆ†æç»„ä»¶"""
    
    def __init__(self):
        super().__init__("lead_lag", "é¢†å…ˆæ»ååˆ†æ")

    def render(self, st_obj, **kwargs) -> Any:
        """
        é‡å†™æ¸²æŸ“æ–¹æ³•ï¼Œè·³è¿‡æ•°æ®çŠ¶æ€æ˜¾ç¤º

        Args:
            st_obj: Streamlitå¯¹è±¡
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            Any: åˆ†æç»“æœ
        """
        try:
            # æ£€æµ‹æ ‡ç­¾é¡µæ¿€æ´»çŠ¶æ€
            tab_index = kwargs.get('tab_index', 0)
            self.detect_tab_activation(st_obj, tab_index)

            # ç›´æ¥è·å–æ•°æ®ï¼Œä¸æ˜¾ç¤ºæ•°æ®çŠ¶æ€ä¿¡æ¯
            data, data_source, data_name = self.get_module_data()

            if data is None:
                st_obj.info("è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼ æ•°æ®æ–‡ä»¶ä»¥è¿›è¡Œåˆ†æ")
                st_obj.markdown(f"""
                **ä½¿ç”¨è¯´æ˜ï¼š**
                1. **æ•°æ®ä¸Šä¼ **ï¼šåœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼ˆå”¯ä¸€ä¸Šä¼ å…¥å£ï¼‰
                2. **æ•°æ®æ ¼å¼**ï¼šç¬¬ä¸€åˆ—ä¸ºæ—¶é—´æˆ³ï¼Œå…¶ä½™åˆ—ä¸ºå˜é‡æ•°æ®
                3. **æ”¯æŒæ ¼å¼**ï¼šCSVã€Excel (.xlsx, .xls)
                4. **ç¼–ç æ”¯æŒ**ï¼šUTF-8ã€GBKã€GB2312ç­‰

                **æ•°æ®å…±äº«è¯´æ˜ï¼š**
                - ä¾§è¾¹æ ä¸Šä¼ çš„æ•°æ®åœ¨ä¸‰ä¸ªåˆ†ææ¨¡å—é—´è‡ªåŠ¨å…±äº«
                - å¹³ç¨³æ€§åˆ†æã€ç›¸å…³æ€§åˆ†æã€é¢†å…ˆæ»ååˆ†æä½¿ç”¨åŒä¸€æ•°æ®æº
                - æ— éœ€é‡å¤ä¸Šä¼ ï¼Œä¸€æ¬¡ä¸Šä¼ å³å¯åœ¨æ‰€æœ‰æ¨¡å—ä¸­ä½¿ç”¨
                """)
                return None

            # æ¸²æŸ“åˆ†æç•Œé¢
            return self.render_analysis_interface(st_obj, data, data_name)

        except Exception as e:
            self.handle_error(st_obj, e, f"æ¸²æŸ“{self.title}ç»„ä»¶")
            return None
    
    def render_analysis_interface(self, st_obj, data: pd.DataFrame, data_name: str) -> Any:
        """
        æ¸²æŸ“é¢†å…ˆæ»ååˆ†æç•Œé¢

        Args:
            st_obj: Streamlitå¯¹è±¡
            data: åˆ†ææ•°æ®
            data_name: æ•°æ®åç§°

        Returns:
            Any: åˆ†æç»“æœ
        """
        try:
                       
            # æ¸²æŸ“é¢†å…ˆæ»ååˆ†æ
            result = self.render_multivariate_screening(st_obj, data, data_name)
            return result

        except Exception as e:
            logger.error(f"æ¸²æŸ“é¢†å…ˆæ»ååˆ†æç•Œé¢æ—¶å‡ºé”™: {e}")
            st_obj.error(f"æ¸²æŸ“åˆ†æç•Œé¢æ—¶å‡ºé”™: {e}")
            return None
    
    def render_multivariate_screening(self, st_obj, data: pd.DataFrame, data_name: str) -> Any:
        """æ¸²æŸ“å¤šå˜é‡é¢†å…ˆæ»åç­›é€‰ç•Œé¢"""
        try:
            # å‚æ•°è®¾ç½®åŒºåŸŸ
            col1, col2 = st_obj.columns(2)
            
            with col1:
                st_obj.markdown("**ç›®æ ‡å˜é‡è®¾ç½®**")
                
                numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()
                if len(numeric_columns) < 2:
                    st_obj.warning("æ•°æ®ä¸­çš„æ•°å€¼å‹å˜é‡å°‘äº2ä¸ªï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
                    return None
                
                target_var = st_obj.selectbox(
                    "é€‰æ‹©ç›®æ ‡å˜é‡",
                    numeric_columns,
                    key="lead_lag_target_var",
                    help="é€‰æ‹©è¦é¢„æµ‹çš„ç›®æ ‡å˜é‡"
                )
                
                # è·å–æ‰€æœ‰å¯é€‰çš„å€™é€‰å˜é‡
                available_candidates = [col for col in numeric_columns if col != target_var]

                candidate_vars = st_obj.multiselect(
                    "é€‰æ‹©å€™é€‰å˜é‡",
                    available_candidates,
                    key="lead_lag_candidate_vars",
                    help="é€‰æ‹©ç”¨äºç­›é€‰çš„å€™é€‰é¢„æµ‹å˜é‡"
                )

                # æ·»åŠ åˆ†ææŒ‰é’®
                if st_obj.button(
                    "å¼€å§‹åˆ†æ",
                    key="lead_lag_analyze_button",
                    type="primary",
                    use_container_width=False
                ):
                    analyze_button = True
                else:
                    analyze_button = False

            with col2:
                st_obj.markdown("**åˆ†æé…ç½®**")
                
                max_lags_val = st_obj.number_input(
                    "æœ€å¤§æ»åæœŸæ•°",
                    min_value=1,
                    max_value=50,
                    value=20,
                    key="lead_lag_max_lags",
                    help="è®¾ç½®è¦åˆ†æçš„æœ€å¤§æ»åæœŸæ•°"
                )
                
                kl_bins_val = st_obj.number_input(
                    "KLæ•£åº¦åˆ†ç®±æ•°",
                    min_value=5,
                    max_value=50,
                    value=10,
                    key="lead_lag_kl_bins",
                    help="è®¾ç½®KLæ•£åº¦è®¡ç®—çš„åˆ†ç®±æ•°é‡"
                )
                
                # æ ‡å‡†åŒ–é…ç½®
                st_obj.markdown("**æ ‡å‡†åŒ–è®¾ç½®**")
                standardize_for_kl = st_obj.checkbox(
                    "KLæ•£åº¦è®¡ç®—æ ‡å‡†åŒ–",
                    value=True,
                    key="lead_lag_standardize_kl",
                    help="æ˜¯å¦å¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ä»¥æé«˜KLæ•£åº¦è®¡ç®—çš„å¯æ¯”æ€§"
                )
                
                standardization_method = st_obj.selectbox(
                    "æ ‡å‡†åŒ–æ–¹æ³•",
                    options=['zscore', 'minmax', 'none'],
                    index=0,
                    key="lead_lag_standardization_method",
                    help="é€‰æ‹©æ ‡å‡†åŒ–æ–¹æ³•ï¼šZ-Scoreæ ‡å‡†åŒ–ã€Min-Maxæ ‡å‡†åŒ–æˆ–ä¸æ ‡å‡†åŒ–",
                    disabled=not standardize_for_kl
                )
                
                # é¢‘ç‡å¯¹é½é…ç½®
                st_obj.markdown("**é¢‘ç‡å¯¹é½è®¾ç½®**")
                enable_frequency_alignment = st_obj.checkbox(
                    "å¯ç”¨æ—¶é—´é¢‘ç‡å¯¹é½",
                    value=True,
                    key="lead_lag_enable_freq_align",
                    help="è‡ªåŠ¨æ£€æµ‹å¹¶å¯¹é½ä¸åŒæ—¶é—´é¢‘ç‡çš„å˜é‡ï¼ˆå¦‚æœˆåº¦vså‘¨åº¦ï¼‰"
                )
                
                col_freq1, col_freq2 = st_obj.columns(2)
                with col_freq1:
                    target_frequency = st_obj.selectbox(
                        "ç›®æ ‡é¢‘ç‡",
                        options=[None, 'Daily', 'Weekly', 'Monthly', 'Quarterly', 'Annual'],
                        index=0,
                        key="lead_lag_target_frequency",
                        help="æŒ‡å®šå¯¹é½ç›®æ ‡é¢‘ç‡ï¼ŒNoneä¸ºè‡ªåŠ¨é€‰æ‹©æœ€ä½é¢‘ç‡",
                        disabled=not enable_frequency_alignment
                    )
                
                with col_freq2:
                    freq_agg_method = st_obj.selectbox(
                        "èšåˆæ–¹æ³•",
                        options=['mean', 'last', 'first', 'sum', 'median'],
                        index=0,
                        key="lead_lag_freq_agg_method",
                        help="é¢‘ç‡å¯¹é½æ—¶çš„æ•°æ®èšåˆæ–¹æ³•",
                        disabled=not enable_frequency_alignment
                    )
            
            if analyze_button and target_var and candidate_vars:
                return self.perform_multivariate_screening(st_obj, data, target_var, candidate_vars, max_lags_val, kl_bins_val, standardize_for_kl, standardization_method, enable_frequency_alignment, target_frequency, freq_agg_method)
            
            # æ˜¾ç¤ºä¹‹å‰çš„ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            results = self.get_state('multivariate_results')
            if results:
                self.render_multivariate_results(st_obj, results)
                
            return results
            
        except Exception as e:
            logger.error(f"æ¸²æŸ“å¤šå˜é‡é¢†å…ˆæ»åç­›é€‰ç•Œé¢æ—¶å‡ºé”™: {e}")
            st_obj.error(f"æ¸²æŸ“å¤šå˜é‡é¢†å…ˆæ»åç­›é€‰ç•Œé¢æ—¶å‡ºé”™: {e}")
            return None
    
    def perform_multivariate_screening(self, st_obj, data: pd.DataFrame, target_var: str, candidate_vars: List[str], max_lags: int, kl_bins: int, standardize_for_kl: bool = True, standardization_method: str = 'zscore', enable_frequency_alignment: bool = True, target_frequency: str = None, freq_agg_method: str = 'mean'):
        """æ‰§è¡Œå¤šå˜é‡é¢†å…ˆæ»åç­›é€‰åˆ†æ"""
        with st_obj.spinner("æ­£åœ¨è¿›è¡Œå¤šå˜é‡é¢†å…ˆæ»åç­›é€‰åˆ†æ..."):
            # æ„å»ºé…ç½®å­—å…¸
            config = {
                'max_lags': max_lags,
                'kl_bins': kl_bins,
                'standardize_for_kl': standardize_for_kl,
                'standardization_method': standardization_method,
                'enable_frequency_alignment': enable_frequency_alignment,
                'target_frequency': target_frequency,
                'freq_agg_method': freq_agg_method
            }

            # è°ƒç”¨åç«¯å‡½æ•°
            results_list, errors, warnings = perform_combined_lead_lag_analysis(
                data, target_var, candidate_vars, config
            )

            # è½¬æ¢ç»“æœä¸ºDataFrame
            if results_list:
                results_df = pd.DataFrame(results_list)
            else:
                results_df = pd.DataFrame()

            results = {
                'target_var': target_var,
                'candidate_vars': candidate_vars,
                'max_lags': max_lags,
                'kl_bins': kl_bins,
                'standardize_for_kl': standardize_for_kl,
                'standardization_method': standardization_method,
                'enable_frequency_alignment': enable_frequency_alignment,
                'target_frequency': target_frequency,
                'freq_agg_method': freq_agg_method,
                'results_df': results_df,
                'errors': errors,
                'warnings': warnings
            }

            # ä¿å­˜ç»“æœ
            self.set_state('multivariate_results', results)

            # æ¸²æŸ“ç»“æœ
            self.render_multivariate_results(st_obj, results)

            return results

    def render_multivariate_results(self, st_obj, results: Dict[str, Any]):
        """æ¸²æŸ“å¤šå˜é‡é¢†å…ˆæ»åç­›é€‰ç»“æœ"""
        try:
            results_df = results['results_df']
            errors = results['errors']
            warnings = results['warnings']

            # æ˜¾ç¤ºé”™è¯¯å’Œè­¦å‘Š
            if errors:
                for error in errors:
                    st_obj.error(f"{error}")

            if warnings:
                for warning in warnings:
                    # è¿‡æ»¤æ‰å†—é•¿çš„é¢‘ç‡å¯¹é½è¯¦ç»†ä¿¡æ¯ï¼Œåªä¿ç•™ç®€æ´æç¤º
                    if "é¢‘ç‡å¯¹é½:" in warning or "é¢‘ç‡æ£€æŸ¥:" in warning:
                        if "[æˆåŠŸ]" in warning or "é¢‘ç‡å¯¹é½æˆåŠŸ" in warning:
                            st_obj.info("å·²å®Œæˆæ—¶é—´é¢‘ç‡å¯¹é½")
                        elif "æ— éœ€å¯¹é½" in warning or "é¢‘ç‡ä¸€è‡´" in warning:
                            st_obj.info("æ—¶é—´é¢‘ç‡ä¸€è‡´ï¼Œæ— éœ€å¯¹é½")
                        elif "å·²ç¦ç”¨" in warning:
                            st_obj.info("é¢‘ç‡å¯¹é½åŠŸèƒ½å·²ç¦ç”¨")
                        elif "[é”™è¯¯]" in warning or "å¤±è´¥" in warning:
                            st_obj.error(f"é¢‘ç‡å¯¹é½å¤±è´¥: {warning}")
                        elif "[ä¿¡æ¯]" in warning:
                            st_obj.info(warning.split(':', 1)[-1].strip() if ':' in warning else warning)
                        else:
                            st_obj.warning(f"é¢‘ç‡å¯¹é½: {warning}")
                    else:
                        st_obj.warning(f"{warning}")

            if results_df is None or results_df.empty:
                st_obj.warning("æ²¡æœ‰åˆ†æç»“æœå¯æ˜¾ç¤º")
                return

            st_obj.markdown("##### ç­›é€‰ç»“æœ")

            # æ ¼å¼åŒ–ç»“æœè¡¨æ ¼
            display_results = results_df.copy()

            # ç§»é™¤ä¸èƒ½åºåˆ—åŒ–çš„åˆ—
            columns_to_remove = ['full_correlogram_df', 'full_kl_divergence_df']
            for col in columns_to_remove:
                if col in display_results.columns:
                    display_results = display_results.drop(columns=[col])

            # åˆ—åæ˜ å°„
            column_mapping = {
                'target_variable': 'ç›®æ ‡å˜é‡',
                'candidate_variable': 'å€™é€‰å˜é‡',
                'k_corr': 'æœ€ä¼˜æ»å(ç›¸å…³)',
                'corr_at_k_corr': 'æœ€å¤§ç›¸å…³ç³»æ•°',
                'k_kl': 'æœ€ä¼˜æ»å(KL)',
                'kl_at_k_kl': 'æœ€å°KLæ•£åº¦',
                'notes': 'å¤‡æ³¨'
            }

            display_results = display_results.rename(columns=column_mapping)

            # æ•°å€¼æ ¼å¼åŒ–
            if 'æœ€å¤§ç›¸å…³ç³»æ•°' in display_results.columns:
                display_results['æœ€å¤§ç›¸å…³ç³»æ•°'] = display_results['æœ€å¤§ç›¸å…³ç³»æ•°'].round(4)
            if 'æœ€å°KLæ•£åº¦' in display_results.columns:
                display_results['æœ€å°KLæ•£åº¦'] = display_results['æœ€å°KLæ•£åº¦'].round(4)

            # ç»“æœæ’åºï¼š1.é¦–å…ˆæŒ‰ç›¸å…³ç³»æ•°ä»1åˆ°-1ï¼Œ2.æœ€ä¼˜æ»åï¼ˆç›¸å…³ï¼‰ç»å¯¹å€¼ä»å°åˆ°å¤§
            if not display_results.empty:
                sort_columns = []
                sort_ascending = []
                
                if 'æœ€å¤§ç›¸å…³ç³»æ•°' in display_results.columns:
                    # æŒ‰ç›¸å…³ç³»æ•°åŸå§‹å€¼é™åºæ’åˆ—ï¼ˆä»1åˆ°-1ï¼‰
                    sort_columns.append('æœ€å¤§ç›¸å…³ç³»æ•°')
                    sort_ascending.append(False)  # é™åºï¼š1, 0.8, 0.5, 0, -0.2, -0.5, -1
                
                if 'æœ€ä¼˜æ»å(ç›¸å…³)' in display_results.columns:
                    # æŒ‰æœ€ä¼˜æ»åæœŸç»å¯¹å€¼å‡åºæ’åˆ—ï¼ˆæ»åæœŸçŸ­çš„åœ¨å‰ï¼‰
                    display_results['_sort_lag_abs'] = display_results['æœ€ä¼˜æ»å(ç›¸å…³)'].abs()
                    sort_columns.append('_sort_lag_abs')
                    sort_ascending.append(True)  # å‡åºï¼š0, 1, 2, 3...
                
                if sort_columns:
                    display_results = display_results.sort_values(
                        by=sort_columns, 
                        ascending=sort_ascending,
                        na_position='last'  # NaNå€¼æ’åœ¨æœ€å
                    )
                    
                    # ç§»é™¤æ’åºè¾…åŠ©åˆ—
                    if '_sort_lag_abs' in display_results.columns:
                        display_results = display_results.drop(columns=['_sort_lag_abs'])
                    
                    # é‡ç½®ç´¢å¼•
                    display_results = display_results.reset_index(drop=True)

            st_obj.dataframe(display_results, use_container_width=True)

            # æ˜¾ç¤ºåˆ†æé…ç½®ä¿¡æ¯
            standardize_info = "å·²å¯ç”¨" if results['standardize_for_kl'] else "æœªå¯ç”¨"
            method_info = results['standardization_method']
            freq_align_info = "å·²å¯ç”¨" if results['enable_frequency_alignment'] else "æœªå¯ç”¨"
            target_freq_info = results['target_frequency'] or 'è‡ªåŠ¨'
            agg_info = results['freq_agg_method']
            
            st_obj.info(f"ğŸ“Š **åˆ†æé…ç½®**: æœ€å¤§æ»åæœŸ: {results['max_lags']}, KLåˆ†ç®±æ•°: {results['kl_bins']}, "
                       f"KLæ ‡å‡†åŒ–: {standardize_info} ({method_info}), "
                       f"é¢‘ç‡å¯¹é½: {freq_align_info} (ç›®æ ‡é¢‘ç‡: {target_freq_info}, èšåˆ: {agg_info})")

            # æä¾›ä¸‹è½½åŠŸèƒ½
            csv_string = display_results.to_csv(index=False, encoding='utf-8-sig')
            csv_data = csv_string.encode('utf-8-sig')
            st_obj.download_button(
                label="ä¸‹è½½ç»“æœ",
                data=csv_data,
                file_name=f"lead_lag_analysis_{results['target_var']}.csv",
                mime="text/csv",
                key="download_lead_lag_data"
            )

            st_obj.divider()

            # è¯¦ç»†å›¾è¡¨å±•ç¤º
            candidate_var_for_plot = st_obj.selectbox(
                "é€‰æ‹©å˜é‡æŸ¥çœ‹è¯¦ç»†å›¾è¡¨",
                results['candidate_vars'],
                key="lead_lag_plot_var",
                help="é€‰æ‹©ä¸€ä¸ªå€™é€‰å˜é‡æŸ¥çœ‹å…¶è¯¦ç»†çš„ç›¸å…³æ€§å’ŒKLæ•£åº¦å›¾è¡¨"
            )

            if candidate_var_for_plot:
                self.render_detailed_multivariate_charts(st_obj, results, candidate_var_for_plot)

        except Exception as e:
            logger.error(f"æ¸²æŸ“å¤šå˜é‡ç»“æœæ—¶å‡ºé”™: {e}")
            st_obj.error(f"æ˜¾ç¤ºç»“æœæ—¶å‡ºé”™: {e}")

    def render_detailed_multivariate_charts(self, st_obj, results: Dict[str, Any], candidate_var: str):
        """æ¸²æŸ“å¤šå˜é‡åˆ†æçš„è¯¦ç»†å›¾è¡¨"""
        # è·å–åŸå§‹æ•°æ®
        data, _, _ = self.get_module_data()
        if data is None:
            st_obj.warning("æ— æ³•è·å–åŸå§‹æ•°æ®")
            return

        # æ„å»ºé…ç½®å­—å…¸
        config = {
            'max_lags': results['max_lags'],
            'kl_bins': results['kl_bins'],
            'standardize_for_kl': results['standardize_for_kl'],
            'standardization_method': results['standardization_method'],
            'enable_frequency_alignment': results['enable_frequency_alignment'],
            'target_frequency': results['target_frequency'],
            'freq_agg_method': results['freq_agg_method']
        }

        detailed_corr_df, detailed_kl_df = get_detailed_lag_data_for_candidate(
            data, results['target_var'], candidate_var, config
        )

        if detailed_corr_df is not None and detailed_kl_df is not None:
            # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
            col1, col2 = st_obj.columns(2)

            with col1:
                st_obj.markdown(f"**{candidate_var} ç›¸å…³æ€§åˆ†æ**")
                if not detailed_corr_df.empty:
                    # é…ç½®matplotlibä»¥ç¦ç”¨å·¥å…·æ 
                    plt.rcParams['toolbar'] = 'None'
                    fig, ax = plt.subplots(figsize=(8, 5))
                    ax.plot(detailed_corr_df['Lag'], detailed_corr_df['Correlation'],
                           marker='o', linewidth=2, markersize=4)
                    ax.set_xlabel('æ»åæœŸ')
                    ax.set_ylabel('ç›¸å…³ç³»æ•°')
                    ax.set_title(f'{results["target_var"]} vs {candidate_var} ç›¸å…³æ€§')
                    ax.grid(True, alpha=0.3)
                    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)
                    plt.tight_layout()
                    st_obj.pyplot(fig, use_container_width=True)
                    plt.close()

            with col2:
                st_obj.markdown(f"**{candidate_var} KLæ•£åº¦åˆ†æ**")
                if not detailed_kl_df.empty:
                    # é…ç½®matplotlibä»¥ç¦ç”¨å·¥å…·æ 
                    plt.rcParams['toolbar'] = 'None'
                    fig, ax = plt.subplots(figsize=(8, 5))
                    ax.plot(detailed_kl_df['Lag'], detailed_kl_df['KL_Divergence'],
                           marker='s', linewidth=2, markersize=4, color='orange')
                    ax.set_xlabel('æ»åæœŸ')
                    ax.set_ylabel('KLæ•£åº¦')
                    ax.set_title(f'{results["target_var"]} vs {candidate_var} KLæ•£åº¦')
                    ax.grid(True, alpha=0.3)
                    plt.tight_layout()
                    st_obj.pyplot(fig, use_container_width=True)
                    plt.close()

        # æ·»åŠ æ—¶é—´åºåˆ—å¯¹æ¯”å›¾
        st_obj.markdown(f"**{results['target_var']} vs {candidate_var} æ—¶é—´åºåˆ—å¯¹æ¯”**")
        self.render_time_series_comparison(st_obj, data, results, candidate_var)

    def render_time_series_comparison(self, st_obj, data: pd.DataFrame, results: Dict[str, Any], candidate_var: str):
        """æ¸²æŸ“ç›®æ ‡å˜é‡ä¸å€™é€‰å˜é‡çš„æ—¶é—´åºåˆ—å¯¹æ¯”å›¾"""
        target_var = results['target_var']

        # æ‰§è¡Œé¢‘ç‡å¯¹é½
        df_aligned = data
        if results['enable_frequency_alignment']:
            df_aligned, alignment_report = align_series_for_analysis(
                data,
                target_var,
                [candidate_var],
                enable_frequency_alignment=True,
                target_frequency=results['target_frequency'],
                agg_method=results['freq_agg_method']
            )

            if alignment_report['status'] == 'error':
                raise ValueError(f"é¢‘ç‡å¯¹é½å¤±è´¥: {alignment_report['error']}")

        # è·å–å¯¹é½åçš„åºåˆ—
        target_series = df_aligned[target_var].copy()
        candidate_series = df_aligned[candidate_var].copy()

        # åˆ é™¤ä»»ä¸€åºåˆ—ä¸­çš„NaNå€¼ï¼ˆä¿æŒç´¢å¼•å¯¹é½ï¼‰
        valid_idx = target_series.notna() & candidate_series.notna()
        target_series_clean = target_series[valid_idx]
        candidate_series_clean = candidate_series[valid_idx]

        if len(target_series_clean) < 2:
            st_obj.warning("æœ‰æ•ˆæ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾")
            return

        # åº”ç”¨æ ‡å‡†åŒ–å¤„ç†ï¼ˆå¦‚æœå¯ç”¨KLæ•£åº¦æ ‡å‡†åŒ–ï¼‰
        if results['standardize_for_kl']:
            standardization_method = results['standardization_method']
            if standardization_method != 'none':
                target_series_plot = standardize_series(target_series_clean, standardization_method)
                candidate_series_plot = standardize_series(candidate_series_clean, standardization_method)
                y_label = f"æ ‡å‡†åŒ–å€¼ ({standardization_method})"
                title_suffix = f" (å·²æ ‡å‡†åŒ– - {standardization_method})"
            else:
                target_series_plot = target_series_clean
                candidate_series_plot = candidate_series_clean
                y_label = "åŸå§‹å€¼"
                title_suffix = " (åŸå§‹å€¼)"
        else:
            target_series_plot = target_series_clean
            candidate_series_plot = candidate_series_clean
            y_label = "åŸå§‹å€¼"
            title_suffix = " (åŸå§‹å€¼)"

        # é…ç½®matplotlibä»¥ç¦ç”¨å·¥å…·æ 
        plt.rcParams['toolbar'] = 'None'

        # åˆ›å»ºæ—¶é—´åºåˆ—å¯¹æ¯”å›¾
        fig, ax = plt.subplots(figsize=(12, 6))

        # ç»˜åˆ¶æ—¶é—´åºåˆ—
        ax.plot(target_series_plot.index, target_series_plot.values,
               label=target_var, linewidth=2, alpha=0.8)
        ax.plot(candidate_series_plot.index, candidate_series_plot.values,
               label=candidate_var, linewidth=2, alpha=0.8)

        # è®¾ç½®å›¾è¡¨æ ·å¼
        ax.set_xlabel('æ—¶é—´')
        ax.set_ylabel(y_label)
        ax.set_title(f'{target_var} vs {candidate_var} æ—¶é—´åºåˆ—å¯¹æ¯”{title_suffix}')
        ax.legend()
        ax.grid(True, alpha=0.3)

        # ä¼˜åŒ–xè½´æ ‡ç­¾æ˜¾ç¤º
        if hasattr(target_series_plot.index, 'to_pydatetime'):
            # å¦‚æœæ˜¯æ—¥æœŸæ—¶é—´ç´¢å¼•ï¼Œä¼˜åŒ–æ˜¾ç¤º
            import matplotlib.dates as mdates
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
            ax.xaxis.set_major_locator(mdates.MonthLocator(interval=max(1, len(target_series_plot) // 10)))
            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')

        plt.tight_layout()
        st_obj.pyplot(fig, use_container_width=True)
        plt.close()