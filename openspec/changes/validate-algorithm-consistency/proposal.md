# 验证DFM核心算法一致性

## Why

### 问题背景

当前项目存在两套DFM实现:
- **train_model**: 原始实现(15,049行),已在生产环境运行,算法正确性已验证
- **train_ref**: 重构实现(约10,800行),代码结构优化,但核心算法一致性未完全验证

**现有验证不足**:
1. Phase 5数值一致性验证仅测试了核心算法参数估计和状态估计(13/13测试通过)
2. 缺少针对**单个核心算法**的独立单元测试对比
3. 缺少基于**完全相同模拟数据**的可控测试环境
4. 端到端测试因baseline格式不匹配而被跳过(13个测试SKIPPED)

**风险**:
- 重构版可能在边界条件下产生数值差异
- PCA初始化、卡尔曼滤波、EM迭代的细微差异可能积累
- 缺少独立验证导致无法定位具体算法模块的问题

### 验证必要性

**关键算法需要独立验证**:
1. **PCA初始化**: 特征值分解、因子载荷初始化、方差贡献计算
2. **卡尔曼滤波**: 预测步骤、更新步骤、数值稳定性处理
3. **卡尔曼平滑**: RTS(Rauch-Tung-Striebel)平滑算法
4. **EM参数估计**: 载荷矩阵、转移矩阵、协方差矩阵估计

**验证策略**:
- **单元测试**: 每个算法独立测试,使用完全相同的模拟数据
- **集成测试**: 完整训练流程对比,使用真实经济数据
- **极严格数值容差标准**: 要求数值**在浮点数计算精度范围内尽可能一致**
  - 使用`numpy.allclose(rtol=1e-10, atol=1e-14)`验证
  - 相对误差容忍度`rtol=1e-10`: 比NumPy默认值(1e-5)严格**10万倍**
  - 绝对误差容忍度`atol=1e-14`: 比machine epsilon大**100倍**,比默认值(1e-8)严格**100万倍**
  - 此标准能检测所有**实质性算法差异**,同时允许浮点数运算的**固有数值误差**(~1e-15量级)
- **严格串行**: 每项测试**必须100%通过**才能进入下一项,发现问题必须找到根因并彻底解决

## What Changes

### 核心变更内容

**新增测试模块**:
1. 创建统一的模拟数据生成器(`tests/consistency/data_generator.py`)
2. 实现单个算法的独立对比测试套件
3. 实现全流程集成对比测试
4. 生成详细的一致性验证报告

**测试范围**:
- PCA算法一致性测试(5个测试场景)
- 卡尔曼滤波一致性测试(6个测试场景)
- 卡尔曼平滑一致性测试(4个测试场景)
- EM参数估计一致性测试(8个测试场景)
- 全流程集成测试(10个测试场景)

**验收标准**:
- 所有单元测试数值**在极严格容差内一致**(使用`np.allclose(rtol=1e-10, atol=1e-14)`)
- 当两边使用完全相同算法时,结果应**逐位完全相等**(使用`np.array_equal`)
- 所有集成测试结果**在极严格容差内一致**(包括最终参数、预测值、评估指标)
- 任何超出容差的不一致必须追查根因并修复,**禁止进一步放宽容差、跳过测试或采用权宜方法**
- 测试覆盖率 > 95%
- 生成详细对比报告和根因分析文档

## Impact

### 影响的规范

- **dfm-algorithm-validation**: DFM核心算法验证能力(新增规范)
- **test-infrastructure**: 测试基础设施增强(扩展现有规范)

### 影响的代码

**新增代码**:
- `dashboard/DFM/train_ref/tests/consistency/data_generator.py`: 模拟数据生成器(约300行)
- `dashboard/DFM/train_ref/tests/consistency/test_pca_consistency.py`: PCA一致性测试(约400行)
- `dashboard/DFM/train_ref/tests/consistency/test_kalman_filter_consistency.py`: 卡尔曼滤波测试(约500行)
- `dashboard/DFM/train_ref/tests/consistency/test_kalman_smoother_consistency.py`: 卡尔曼平滑测试(约350行)
- `dashboard/DFM/train_ref/tests/consistency/test_em_estimation_consistency.py`: EM估计测试(约600行)
- `dashboard/DFM/train_ref/tests/consistency/test_full_pipeline_consistency.py`: 全流程测试(约800行)
- `dashboard/DFM/train_ref/tests/consistency/report_generator.py`: 报告生成器(约250行)

**修改代码**:
- `dashboard/DFM/train_ref/tests/consistency/base.py`: 扩展基类工具函数(约50行修改)
- `openspec/changes/refactor-dfm-train-model/tasks.md`: 更新Phase 5任务状态

**总代码量**: 约3,200行新增测试代码 + 50行修改

### 代码结构对比

| 模块 | 现有验证 | 新增验证 | 覆盖率提升 |
|------|---------|---------|-----------|
| PCA初始化 | 端到端测试(间接) | 5个独立单元测试 | 0% → 100% |
| 卡尔曼滤波 | 13个核心测试 | 6个对比测试 | 86% → 95% |
| 卡尔曼平滑 | 状态估计测试(6个) | 4个独立测试 | 80% → 95% |
| EM参数估计 | 参数估计测试(7个) | 8个详细测试 | 84% → 98% |
| 全流程集成 | 13个SKIPPED | 10个完整测试 | 0% → 100% |

### 风险与缓解

**风险**:
1. 测试开发工作量较大(约5周)
2. 可能发现train_ref的数值不一致问题,需要修复
3. 模拟数据可能无法覆盖所有真实场景

**缓解措施**:
1. **严格串行执行**: Phase N的所有测试100%通过后才能开始Phase N+1
2. **根因分析流程**: 发现任何数值差异,必须:
   - 逐步追踪到具体代码行
   - 分析差异产生的数学或实现原因
   - 修复train_ref代码使其与train_model完全一致
   - 回归测试确认修复有效
   - 记录问题和解决方案到文档
3. **禁止权宜方法**: 严禁通过放宽容差、跳过测试、近似处理等方式绕过问题
4. **详细日志**: 记录每个数组/矩阵的完整数值,便于逐位对比
5. **双重验证**: 模拟数据(可控)+真实数据(生产场景)全面覆盖

### 预期收益

**质量保证**:
- 100%核心算法数值一致性验证
- 95%+测试覆盖率
- 详细的验证报告和问题跟踪

**风险降低**:
- 消除train_ref部署前的最大不确定性
- 为Phase 9删除train_model提供信心保证
- 建立长期的算法回归测试基础设施

**开发效率**:
- 未来算法优化可快速验证一致性
- 问题定位更精准(单元测试级别)
- 减少生产环境bug风险
