# DFMè®­ç»ƒæ¨¡å—å®Œå…¨é‡æ„è®¾è®¡æ–‡æ¡£

## Context

å½“å‰HTFAé¡¹ç›®ä¸­å­˜åœ¨ä¸¤ä¸ªDFMè®­ç»ƒå®ç°ï¼š
- `train_model/`ï¼šåŸå§‹å®ç°ï¼ˆ15,049è¡Œï¼Œ24ä¸ªæ–‡ä»¶ï¼‰
- `train_ref/`ï¼šé‡æ„ç‰ˆæœ¬ï¼ˆ2,673è¡Œï¼Œå®é™…åŠŸèƒ½ä»…è¦†ç›–40%ï¼‰

ç»è¿‡æ·±åº¦ä»£ç åˆ†æå‘ç°ï¼Œtrain_refçš„æ ¸å¿ƒç®—æ³•å±‚å·²å®Œæˆï¼Œä½†å…³é”®åŠŸèƒ½æ¨¡å—ç¼ºå¤±ï¼š
- å˜é‡é€‰æ‹©å±‚ï¼ˆselection/ï¼‰- 1,200è¡Œç¼ºå¤±
- è®­ç»ƒåè°ƒå±‚ï¼ˆtraining/trainer.py, pipeline.pyï¼‰- 3,500è¡Œç¼ºå¤±
- åˆ†æè¾“å‡ºå±‚ï¼ˆanalysis/ï¼‰- 3,300è¡Œç¼ºå¤±
- é¢„è®¡ç®—å¼•æ“ï¼ˆoptimization/precompute.pyï¼‰- 800è¡Œç¼ºå¤±

**é‡‡ç”¨å®Œå…¨é‡æ„**ï¼šé‡æ–°å®ç°æ‰€æœ‰ç¼ºå¤±æ¨¡å—ï¼Œå½»åº•è§£å†³æ¶æ„é—®é¢˜ã€‚

**train_modelå¤„ç†ç­–ç•¥**ï¼š
- âš ï¸ åœ¨æ‰€æœ‰é‡æ„å·¥ä½œã€ä¸€è‡´æ€§éªŒè¯ã€ç”¨æˆ·æµ‹è¯•å®Œæˆå‰ï¼Œ**ä¸å¾—åˆ é™¤**train_modelæ¨¡å—
- ğŸ“– train_modelä»£ç ä»…ä½œä¸º**å‚è€ƒ**ï¼Œä¸å¾—è¢«è°ƒç”¨æˆ–ä¿®æ”¹
- âœ… åªæœ‰åœ¨ç”Ÿäº§ç¯å¢ƒç¨³å®šè¿è¡Œåï¼Œæ‰åœ¨Phase 9åˆ é™¤train_model

**åˆ†æ”¯ç®¡ç†ç­–ç•¥**ï¼š
- ğŸŒ¿ æ‰€æœ‰é‡æ„å·¥ä½œåœ¨`feature/refactor-train-model`åˆ†æ”¯è¿›è¡Œ
- ğŸš« é‡æ„æœŸé—´ä¸å¾—åˆå¹¶åˆ°mainåˆ†æ”¯
- âœ… åªæœ‰åœ¨Phase 9ï¼ˆæ¸…ç†ä¸åˆå¹¶ï¼‰å®Œå…¨å®Œæˆåï¼Œæ‰åˆå¹¶åˆ°main

## Goals / Non-Goals

### Goals

1. **åŠŸèƒ½ç­‰ä»·**ï¼šé‡æ–°å®ç°ä¸train_modelå®Œå…¨ç›¸åŒçš„åŠŸèƒ½
2. **æ•°å€¼ä¸€è‡´**ï¼šç›¸åŒè¾“å…¥ä¸‹ï¼Œè¾“å‡ºç»“æœæ•°å€¼è¯¯å·® < 1e-6
3. **æ¶æ„æ¸…æ™°**ï¼šåˆ†å±‚æ˜ç¡®ï¼ŒèŒè´£å•ä¸€ï¼Œæ˜“äºç»´æŠ¤
4. **ä»£ç è´¨é‡**ï¼šéµå¾ªKISSã€DRYã€YAGNIã€SOCã€SRPåŸåˆ™
5. **é«˜æµ‹è¯•è¦†ç›–**ï¼šæ ¸å¿ƒç®—æ³•å±‚ > 90%ï¼Œå…¶ä»–å±‚ > 80%
6. **å½»åº•æ¶ˆé™¤æŠ€æœ¯å€º**ï¼šä¸ä¿ç•™ä»»ä½•é—ç•™ä»£ç 

### Non-Goals

1. **ä¿ç•™å…¼å®¹**ï¼šä¸æä¾›train_modelä¸train_refçš„å…¼å®¹å±‚æˆ–å›é€€æœºåˆ¶
2. **æ€§èƒ½ä¼˜åŒ–**ï¼šä¸å¼•å…¥è¶…å‡ºtrain_modelçš„æ–°ä¼˜åŒ–ï¼ˆå¦‚GPUåŠ é€Ÿï¼‰
3. **åŠŸèƒ½æ‰©å±•**ï¼šä¸æ·»åŠ train_modelä¸æ”¯æŒçš„æ–°åŠŸèƒ½ï¼ˆå¦‚å¢é‡è®­ç»ƒï¼‰
4. **æ›´æ”¹æ•°æ®æ ¼å¼**ï¼šä¿æŒè¾“å…¥è¾“å‡ºæ ¼å¼ä¸train_modelä¸€è‡´

## Decisions

### 1. ç²¾ç®€åˆ†å±‚æ¶æ„ï¼ˆæ–¹æ¡ˆBï¼‰

é‡‡ç”¨ç²¾ç®€çš„5å±‚æ¶æ„è®¾è®¡ï¼Œé¿å…è¿‡åº¦æŠ½è±¡ï¼š

```
train_ref/
â”œâ”€â”€ core/           # æ ¸å¿ƒç®—æ³•å±‚ï¼ˆå¡å°”æ›¼æ»¤æ³¢ã€DFMæ¨¡å‹ã€EMä¼°è®¡ï¼‰750è¡Œ
â”‚   â”œâ”€â”€ kalman.py
â”‚   â”œâ”€â”€ factor_model.py
â”‚   â””â”€â”€ estimator.py
â”œâ”€â”€ selection/      # å˜é‡é€‰æ‹©å±‚ï¼ˆåå‘é€‰æ‹©å™¨ï¼‰1,200è¡Œ
â”‚   â””â”€â”€ backward_selector.py
â”œâ”€â”€ training/       # è®­ç»ƒåè°ƒå±‚ï¼ˆè®­ç»ƒå™¨+è¯„ä¼°å™¨+pipeline+é…ç½®ï¼‰4,350è¡Œ
â”‚   â”œâ”€â”€ trainer.py
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ analysis/       # åˆ†æè¾“å‡ºå±‚ï¼ˆæŠ¥å‘Š+åˆ†æ+å¯è§†åŒ–ï¼‰3,900è¡Œ
â”‚   â”œâ”€â”€ reporter.py
â”‚   â”œâ”€â”€ analysis_utils.py
â”‚   â””â”€â”€ visualizer.py
â”œâ”€â”€ utils/          # å·¥å…·å±‚ï¼ˆæ•°æ®+ç¼“å­˜+é¢„è®¡ç®—ï¼‰600è¡Œ
â”‚   â”œâ”€â”€ data_utils.py
â”‚   â”œâ”€â”€ cache.py
â”‚   â””â”€â”€ precompute.py
â””â”€â”€ facade.py       # ç»Ÿä¸€APIå…¥å£
```

**æ€»è®¡**: 10,800è¡Œï¼Œ5ä¸ªç›®å½•ï¼Œ12ä¸ªæ–‡ä»¶ï¼ˆä¸å«__init__.pyï¼‰

**ç²¾ç®€åŸåˆ™**ï¼š
- âœ… åˆ é™¤è¿‡åº¦æŠ½è±¡ï¼šinterfaces, wrapper, selection_engine
- âœ… åˆå¹¶é«˜åº¦è€¦åˆæ¨¡å—ï¼ševaluationâ†’training, pipelineâ†’trainer
- âœ… ç¬¦åˆKISSåŸåˆ™ï¼Œä»£ç å‡å°‘28% (vs train_model)
- âœ… ä¿ç•™æ ¸å¿ƒåˆ†å±‚ï¼ŒèŒè´£æ¸…æ™°
- âœ… æ˜“äºç†è§£å’Œç»´æŠ¤ï¼ˆé€‚åˆ1-2äººå›¢é˜Ÿï¼‰

### 2. å˜é‡é€‰æ‹©å®ç°ç­–ç•¥

**å†³ç­–**ï¼šé‡æ–°å®ç°åå‘é€æ­¥å˜é‡é€‰æ‹©ç®—æ³•

**æ ¸å¿ƒç®—æ³•**ï¼š
```python
# selection/backward_selector.py
class BackwardSelector:
    def __init__(self, evaluator, precompute_engine):
        """
        Args:
            evaluator: ModelEvaluatorå®ä¾‹ï¼ˆæ¥è‡ªtraining.trainerï¼‰
            precompute_engine: PrecomputeEngineå®ä¾‹ï¼ˆæ¥è‡ªutils.precomputeï¼‰
        """
        self.evaluator = evaluator
        self.precompute = precompute_engine

    def select(self,
               data: pd.DataFrame,
               target_col: str,
               initial_variables: List[str],
               criterion: str = 'rmse',
               progress_callback: Optional[Callable] = None) -> SelectionResult:
        """åå‘é€æ­¥å˜é‡é€‰æ‹©

        ç®—æ³•æµç¨‹ï¼š
        1. ä»å…¨éƒ¨å˜é‡å¼€å§‹
        2. é€ä¸ªå°è¯•å‰”é™¤æ¯ä¸ªå˜é‡
        3. è¯„ä¼°å‰”é™¤åçš„æ¨¡å‹æ€§èƒ½
        4. é€‰æ‹©æ€§èƒ½æå‡æœ€å¤§çš„å˜é‡å‰”é™¤
        5. é‡å¤ç›´åˆ°æ— æ³•æå‡
        """
        current_vars = initial_variables.copy()
        selection_history = []

        # é¢„è®¡ç®—åæ–¹å·®çŸ©é˜µåŠ é€Ÿè¯„ä¼°
        precomputed_ctx = self.precompute.compute(data[current_vars + [target_col]])

        while len(current_vars) > 1:
            best_score = -np.inf
            best_var_to_remove = None

            # å°è¯•å‰”é™¤æ¯ä¸ªå˜é‡
            for var in current_vars:
                candidate_vars = [v for v in current_vars if v != var]
                score = self._evaluate_subset(
                    data, candidate_vars, target_col, criterion, precomputed_ctx
                )

                if score > best_score:
                    best_score = score
                    best_var_to_remove = var

            # æ£€æŸ¥æ˜¯å¦åœæ­¢
            baseline_score = self._evaluate_subset(
                data, current_vars, target_col, criterion, precomputed_ctx
            )

            if best_score <= baseline_score:
                break

            # å‰”é™¤å˜é‡å¹¶è®°å½•
            current_vars.remove(best_var_to_remove)
            selection_history.append({
                'removed_variable': best_var_to_remove,
                'score': best_score,
                'remaining_vars': current_vars.copy()
            })

            if progress_callback:
                progress_callback(f"[SELECTION] å‰”é™¤: {best_var_to_remove}, "
                                f"å‰©ä½™: {len(current_vars)}, å¾—åˆ†: {best_score:.4f}")

        return SelectionResult(
            selected_variables=current_vars,
            selection_history=selection_history,
            final_score=best_score
        )
```

**ç†ç”±**ï¼š
- å®Œå…¨æ§åˆ¶ç®—æ³•å®ç°ï¼Œæ˜“äºè°ƒè¯•
- ä¾èµ–æ³¨å…¥ä¾¿äºæµ‹è¯•
- ä½¿ç”¨é¢„è®¡ç®—å¼•æ“ä¼˜åŒ–æ€§èƒ½

**å®ç°è¦ç‚¹**ï¼š
1. å‚è€ƒtrain_model/variable_selection.pyçš„æ ¸å¿ƒé€»è¾‘
2. æ”¯æŒRMSEå’ŒHit RateåŒç›®æ ‡ä¼˜åŒ–
3. å®Œæ•´çš„å•å…ƒæµ‹è¯•ï¼ˆ>85%è¦†ç›–ç‡ï¼‰

### 3. è®­ç»ƒæµç¨‹ç¼–æ’ï¼ˆåˆå¹¶åˆ°DFMTrainerï¼‰

**å†³ç­–**ï¼šå°†Pipelineé€»è¾‘åˆå¹¶åˆ°DFMTrainerï¼Œé¿å…ä¸å¿…è¦çš„æŠ½è±¡

```python
# training/trainer.py

class ModelEvaluator:
    """æ¨¡å‹è¯„ä¼°å™¨ï¼ˆåŸevaluation/evaluator.pyï¼‰"""
    def calculate_rmse(self, predictions, actuals):
        return np.sqrt(np.mean((predictions - actuals) ** 2))

    def calculate_hit_rate(self, predictions, actuals, previous_values):
        pred_direction = np.sign(predictions - previous_values)
        actual_direction = np.sign(actuals - previous_values)
        return np.mean(pred_direction == actual_direction)

    def evaluate(self, model, data, train_end, validation_range):
        # æ ·æœ¬å†…å’Œæ ·æœ¬å¤–è¯„ä¼°
        ...


class DFMTrainer:
    """ä¸»è®­ç»ƒå™¨ï¼ˆåŒ…å«åŸpipeline.pyé€»è¾‘ï¼‰"""
    def __init__(self, config: TrainingConfig):
        self.config = config
        self.evaluator = ModelEvaluator()

        # ç¯å¢ƒåˆå§‹åŒ–
        self._init_environment()

    def _init_environment(self):
        """ç¯å¢ƒåˆå§‹åŒ–å’Œå¯é‡ç°æ€§æ§åˆ¶"""
        import os, multiprocessing, random, numpy as np

        # å¤šçº¿ç¨‹BLASé…ç½®
        cpu_count = multiprocessing.cpu_count()
        os.environ['OMP_NUM_THREADS'] = str(cpu_count)
        os.environ['MKL_NUM_THREADS'] = str(cpu_count)

        # éšæœºç§å­è®¾ç½®
        SEED = 42
        random.seed(SEED)
        np.random.seed(SEED)

    def train(self, progress_callback=None) -> TrainingResult:
        """å®Œæ•´ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼ˆåŸpipeline.runï¼‰"""
        # é˜¶æ®µ1ï¼šå˜é‡é€‰æ‹©ï¼ˆå›ºå®šk=å—æ•°ï¼‰
        selected_vars = self._run_variable_selection(progress_callback)

        # é˜¶æ®µ2ï¼šå› å­æ•°é€‰æ‹©ï¼ˆPCA/Elbow/Fixedï¼‰
        k_factors, pca_analysis = self._select_num_factors(
            selected_vars, progress_callback
        )

        # æœ€ç»ˆè®­ç»ƒ
        results = self._train_final_model(
            selected_vars, k_factors, progress_callback
        )

        return results

    def _run_variable_selection(self, progress_callback):
        """é˜¶æ®µ1ï¼šå˜é‡é€‰æ‹©ï¼ˆåŸpipeline._run_stage1ï¼‰"""
        if not self.config.enable_variable_selection:
            return self.config.selected_indicators

        from selection.backward_selector import BackwardSelector
        from utils.precompute import PrecomputeEngine

        data = load_data(self.config.data_path)
        selector = BackwardSelector(
            evaluator=self.evaluator,
            precompute_engine=PrecomputeEngine()
        )
        result = selector.select(
            data=data,
            target_col=self.config.target_variable,
            initial_variables=self.config.selected_indicators,
            progress_callback=progress_callback
        )
        return result.selected_variables

    def _select_num_factors(self, selected_vars, progress_callback):
        """é˜¶æ®µ2ï¼šå› å­æ•°é€‰æ‹©ï¼ˆåŸpipeline._run_stage2ï¼‰"""
        if self.config.factor_selection_method == 'fixed':
            return self.config.k_factors, None

        # PCAåˆ†æ
        from sklearn.decomposition import PCA
        data = load_data(self.config.data_path)[selected_vars]
        pca = PCA()
        pca.fit(data)

        if self.config.factor_selection_method == 'cumulative':
            cumsum = np.cumsum(pca.explained_variance_ratio_)
            k = np.argmax(cumsum >= self.config.pca_threshold) + 1
        elif self.config.factor_selection_method == 'elbow':
            marginal_variance = np.diff(pca.explained_variance_ratio_)
            k = np.argmax(marginal_variance < self.config.elbow_threshold) + 1

        return k, pca

    def _train_final_model(self, selected_vars, k_factors, progress_callback):
        """æœ€ç»ˆæ¨¡å‹è®­ç»ƒï¼ˆåŸpipeline._run_final_trainingï¼‰"""
        from core.estimator import EMEstimator

        # åŠ è½½æ•°æ®
        data = load_data(self.config.data_path)[selected_vars]

        # EMä¼°è®¡
        estimator = EMEstimator()
        params = estimator.estimate(
            data=data,
            k_factors=k_factors,
            max_iter=self.config.max_iterations,
            progress_callback=progress_callback
        )

        # è¯„ä¼°
        metrics = self.evaluator.evaluate(params, data, self.config)

        return TrainingResult(params=params, metrics=metrics)
```

**ç²¾ç®€ç†ç”±**ï¼š
- âœ… åˆ é™¤pipeline.pyï¼Œå‡å°‘æ–‡ä»¶æ•°
- âœ… trainer.pyåŒ…å«å®Œæ•´æµç¨‹ï¼Œæ˜“äºç†è§£
- âœ… è¯„ä¼°å™¨åˆå¹¶åˆ°trainer.pyï¼Œé¿å…è·¨æ–‡ä»¶è·³è½¬
- âœ… ä»ä¿æŒæ¸…æ™°çš„ç§æœ‰æ–¹æ³•åˆ†æ®µ

### 4. ç»“æœåˆ†æå±‚å®ç°ï¼ˆåˆå¹¶generate_reportï¼‰

**å†³ç­–**ï¼šåˆå¹¶generate_report.pyåˆ°reporter.pyï¼Œé¿å…ç®€å•åŒ…è£…

```python
# analysis/reporter.pyï¼ˆåŒ…å«åŸgenerate_report.pyé€»è¾‘ï¼‰
class AnalysisReporter:
    def generate_report_with_params(self, results, output_dir, var_industry_map=None):
        """å‚æ•°åŒ–æŠ¥å‘Šç”Ÿæˆï¼ˆåŸgenerate_report.pyä¸»å‡½æ•°ï¼‰"""
        # æ–‡ä»¶è·¯å¾„ç®¡ç†
        pca_path = os.path.join(output_dir, 'pca_analysis.xlsx')
        contrib_path = os.path.join(output_dir, 'contribution_analysis.xlsx')
        r2_path = os.path.join(output_dir, 'r2_analysis.xlsx')

        # ç”Ÿæˆå„ç±»æŠ¥å‘Š
        self.generate_pca_report(results.pca_analysis, pca_path)
        self.generate_contribution_report(results, contrib_path, var_industry_map)
        self.generate_r2_report(results, r2_path)

        # ç”Ÿæˆå¯è§†åŒ–
        from analysis.visualizer import ResultVisualizer
        visualizer = ResultVisualizer()
        visualizer.plot_forecast_vs_actual(results, output_dir)
        visualizer.plot_factor_loadings(results, output_dir)

    def generate_pca_report(self, pca_analysis, output_path):
        """PCAæ–¹å·®è´¡çŒ®åˆ†æ"""
        eigenvalues = pca_analysis.eigenvalues
        variance_ratios = eigenvalues / np.sum(eigenvalues)
        cumulative_variance = np.cumsum(variance_ratios)

        df = pd.DataFrame({
            'å› å­ç´¢å¼•': range(1, len(eigenvalues) + 1),
            'ç‰¹å¾å€¼': eigenvalues,
            'æ–¹å·®è´¡çŒ®ç‡': variance_ratios,
            'ç´¯ç§¯æ–¹å·®è´¡çŒ®ç‡': cumulative_variance
        })

        # Excelå¤šSheetå†™å…¥å’Œæ ¼å¼åŒ–
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='PCAåˆ†æ', index=False)
            self._format_excel_sheet(writer.sheets['PCAåˆ†æ'])

    def generate_contribution_report(self, results, output_path, var_industry_map):
        """å› å­è´¡çŒ®åº¦åˆ†è§£ï¼ˆæŒ‰æŒ‡æ ‡ã€æŒ‰è¡Œä¸šï¼‰"""
        from analysis.analysis_utils import calculate_factor_contributions

        # ä½¿ç”¨å·¥å…·å‡½æ•°è®¡ç®—
        contrib_df = calculate_factor_contributions(
            factors=results.factors,
            loadings=results.loadings,
            data_std=results.data_std,
            var_industry_map=var_industry_map
        )

        # ä¿å­˜åˆ°Excel
        ...

    def _format_excel_sheet(self, worksheet, column_widths=None):
        """Excelæ ¼å¼åŒ–ï¼ˆåŸresults_analysis.pyä¸­çš„å·¥å…·å‡½æ•°ï¼‰"""
        from openpyxl.styles import Font, Alignment, PatternFill
        ...
```

**ç²¾ç®€ç†ç”±**ï¼š
- âœ… åˆ é™¤generate_report.pyï¼ˆçœ300è¡Œï¼‰
- âœ… reporter.pyåŒ…å«å®Œæ•´æŠ¥å‘Šç”Ÿæˆé€»è¾‘
- âœ… é¿å…ç®€å•åŒ…è£…å™¨ï¼Œå‡å°‘æ–‡ä»¶è·³è½¬
- âœ… Excelæ ¼å¼åŒ–ç­‰å·¥å…·å‡½æ•°å†…è”åˆ°reporter.py

### 5. æ•°å€¼ä¸€è‡´æ€§ä¿è¯æœºåˆ¶

**å†³ç­–**ï¼šé‡‡ç”¨ä¸¥æ ¼çš„å¯¹æ¯”æµ‹è¯•æ¡†æ¶

```python
# tests/consistency/test_end_to_end.py
class TestNumericConsistency:
    def test_parameter_estimation(self):
        """éªŒè¯EMç®—æ³•å‚æ•°ä¼°è®¡ç»“æœä¸€è‡´"""
        # åŠ è½½ç›¸åŒæ•°æ®å’Œé…ç½®
        data = load_test_data()
        config = create_test_config()

        # è¿è¡Œtrain_refï¼ˆåœ¨åˆ é™¤train_modelå‰ä¿ç•™å¯¹æ¯”ï¼‰
        from dashboard.DFM.train_ref import DFMTrainer
        new_result = DFMTrainer(config).train()

        # åŠ è½½train_modelçš„åŸºå‡†ç»“æœ
        baseline_result = load_baseline_results('test_case_1.pkl')

        # éªŒè¯å‚æ•°çŸ©é˜µ
        assert np.linalg.norm(new_result.params.A - baseline_result.params.A) < 1e-6
        assert np.linalg.norm(new_result.params.Q - baseline_result.params.Q) < 1e-6
        assert np.linalg.norm(new_result.params.H - baseline_result.params.H) < 1e-6
        assert np.linalg.norm(new_result.params.R - baseline_result.params.R) < 1e-6

    def test_forecast_consistency(self):
        """éªŒè¯é¢„æµ‹ç»“æœä¸€è‡´"""
        # å¯¹æ¯”æ¯ä¸ªæ—¶é—´ç‚¹çš„é¢„æµ‹å€¼
        for t in range(len(new_result.forecast_oos)):
            assert abs(new_result.forecast_oos[t] - baseline_result.forecast_oos[t]) < 1e-6

    def test_metrics_consistency(self):
        """éªŒè¯è¯„ä¼°æŒ‡æ ‡ä¸€è‡´"""
        assert abs(new_result.metrics.rmse_oos - baseline_result.metrics.rmse_oos) < 1e-4
        assert abs(new_result.metrics.hit_rate_oos - baseline_result.metrics.hit_rate_oos) < 0.01
```

**å®æ–½æ­¥éª¤**ï¼š
1. åœ¨åˆ é™¤train_modelå‰ï¼Œè¿è¡Œtrain_modelå¹¶ä¿å­˜æ‰€æœ‰ç»“æœä½œä¸ºbaseline
2. å®ç°train_refæ–°æ¨¡å—æ—¶ï¼ŒæŒç»­å¯¹æ¯”baselineéªŒè¯æ•°å€¼ä¸€è‡´æ€§
3. æ‰€æœ‰å¯¹æ¯”æµ‹è¯•é€šè¿‡åï¼Œæ‰å¯åˆ é™¤train_model

### 6. UIå±‚ç›´æ¥åˆ‡æ¢

**å†³ç­–**ï¼šç›´æ¥ä¿®æ”¹UIä½¿ç”¨train_refï¼Œä¸ä¿ç•™ç‰ˆæœ¬åˆ‡æ¢

```python
# dashboard/ui/pages/dfm/model_training_page.py

# æ—§ä»£ç ï¼ˆåˆ é™¤ï¼‰
# from dashboard.DFM.train_model.tune_dfm import run_tuning
# results = run_tuning(...)

# æ–°ä»£ç 
from dashboard.DFM.train_ref import DFMTrainer, TrainingConfig

# æ„å»ºé…ç½®
config = TrainingConfig(
    data=DataConfig(
        data_path=selected_file,
        target_variable=target_var,
        ...
    ),
    model=ModelConfig(
        k_factors=k_factors,
        max_iter=max_iterations,
        ...
    ),
    selection=SelectionConfig(
        enable=enable_selection,
        method='backward',
        criterion='rmse'
    )
)

# è®­ç»ƒ
trainer = DFMTrainer(config)
results = trainer.train(progress_callback=lambda msg: update_progress(msg))
```

**ç†ç”±**ï¼š
- ç®€åŒ–ä»£ç ï¼Œæ— éœ€ç»´æŠ¤ç‰ˆæœ¬åˆ‡æ¢é€»è¾‘
- ç”¨æˆ·ä½“éªŒå®Œå…¨ä¸€è‡´ï¼ˆæ¥å£ä¿æŒä¸å˜ï¼‰
- å½»åº•ç§»é™¤é—ç•™ä»£ç 

## Risks / Trade-offs

### é£é™©1ï¼šæ•°å€¼ç²¾åº¦å·®å¼‚

**æè¿°**ï¼šé‡æ–°å®ç°ç®—æ³•å¯èƒ½å¼•å…¥å¾®å°æ•°å€¼è¯¯å·®

**ç¼“è§£**ï¼š
- å‚è€ƒtrain_modelå®ç°ï¼Œç¡®ä¿ç®—æ³•é€»è¾‘æ­£ç¡®
- å»ºç«‹å…¨é¢çš„å¯¹æ¯”æµ‹è¯•ï¼ˆè¯¯å·® < 1e-6ï¼‰
- ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­å’Œæ•°å€¼åº“ç‰ˆæœ¬

**æ¥å—åº¦**ï¼šRMSEå·®å¼‚ < 1e-4å¯æ¥å—

### é£é™©2ï¼šå¼€å‘å‘¨æœŸé•¿

**æè¿°**ï¼š22å‘¨å¼€å‘å‘¨æœŸå¯èƒ½å½±å“å…¶ä»–é¡¹ç›®

**ç¼“è§£**ï¼š
- åˆ†é˜¶æ®µå¼€å‘ï¼Œæ¯ä¸ªé˜¶æ®µéƒ½æœ‰å¯äº¤ä»˜æˆæœ
- å¹¶è¡Œå¼€å‘å¤šä¸ªæ¨¡å—ï¼ˆé€‰æ‹©å±‚ã€åˆ†æå±‚ï¼‰
- æŒç»­é›†æˆå’Œæµ‹è¯•ï¼ŒåŠæ—©å‘ç°é—®é¢˜

### é£é™©3ï¼šå¤æ‚ç®—æ³•å®ç°éš¾åº¦é«˜

**æè¿°**ï¼šå˜é‡é€‰æ‹©ã€ç»“æœåˆ†æç­‰ç®—æ³•å¤æ‚åº¦é«˜

**ç¼“è§£**ï¼š
- æ·±å…¥ç ”ç©¶train_modelå®ç°
- åˆ†æ­¥å®ç°ï¼Œå…ˆå®ç°æ ¸å¿ƒé€»è¾‘å†ä¼˜åŒ–
- é«˜æµ‹è¯•è¦†ç›–ç‡ï¼ˆ>90%ï¼‰

### å…³é”®æƒè¡¡

1. **å¼€å‘æ—¶é—´ vs é•¿æœŸç»´æŠ¤**ï¼š22å‘¨æ¢å–60%ç»´æŠ¤æˆæœ¬é™ä½
2. **é£é™© vs æ”¶ç›Š**ï¼šé«˜é£é™©æ¢å–å½»åº•è§£å†³æŠ€æœ¯å€ºåŠ¡
3. **å®Œç¾ vs å®ç”¨**ï¼šä¸å¼•å…¥æ–°ä¼˜åŒ–ï¼Œä¸“æ³¨åŠŸèƒ½ç­‰ä»·

## Migration Plan

### Phase 1ï¼šå‡†å¤‡é˜¶æ®µï¼ˆ1å‘¨ï¼‰

1. è¿è¡Œtrain_modelç”Ÿæˆæ‰€æœ‰baselineç»“æœ
2. ä¿å­˜baselineåˆ°tests/consistency/baseline/
3. åˆ›å»ºfeatureåˆ†æ”¯è¿›è¡Œå¼€å‘

### Phase 2ï¼šæ ¸å¿ƒå¼€å‘ï¼ˆ16å‘¨ï¼‰

**Week 1-3**ï¼šå˜é‡é€‰æ‹©å±‚
- å®ç°BackwardSelector
- å®ç°SelectionEngine
- å•å…ƒæµ‹è¯•ï¼ˆè¦†ç›–ç‡ > 85%ï¼‰

**Week 4-7**ï¼šè®­ç»ƒåè°ƒå±‚
- å®ç°TrainingPipeline
- å®ç°DFMTrainer
- è¡¥å……é…ç½®ç±»
- å•å…ƒæµ‹è¯•ï¼ˆè¦†ç›–ç‡ > 80%ï¼‰

**Week 8-11**ï¼šåˆ†æè¾“å‡ºå±‚
- å®ç°AnalysisReporter
- å®ç°ResultVisualizer
- å®ç°åˆ†æå·¥å…·å‡½æ•°
- å•å…ƒæµ‹è¯•ï¼ˆè¦†ç›–ç‡ > 80%ï¼‰

**Week 12-13**ï¼šä¼˜åŒ–å±‚
- å®ç°PrecomputeEngine
- å®ç°ä¼˜åŒ–è¯„ä¼°å™¨
- æ€§èƒ½æµ‹è¯•

**Week 14-16**ï¼šé›†æˆæµ‹è¯•
- ç«¯åˆ°ç«¯å¯¹æ¯”æµ‹è¯•
- æ•°å€¼ä¸€è‡´æ€§éªŒè¯
- æ€§èƒ½åŸºå‡†æµ‹è¯•

### Phase 3ï¼šUIè¿ç§»ï¼ˆ2å‘¨ï¼‰

1. ä¿®æ”¹model_training_page.py
2. ä¿®æ”¹ç›¸å…³ç»„ä»¶
3. å…¨é¢UIæµ‹è¯•

### Phase 4ï¼šä¸Šçº¿ï¼ˆ2å‘¨ï¼‰

1. ä»£ç å®¡æŸ¥
2. éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ
3. ç”¨æˆ·éªŒæ”¶æµ‹è¯•
4. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

### Phase 5ï¼šæ¸…ç†ä¸åˆå¹¶ï¼ˆ1å‘¨ï¼‰

**å‰ç½®æ¡ä»¶**ï¼š
- Phase 4æ‰€æœ‰æµ‹è¯•å’Œéƒ¨ç½²å·²å®Œæˆ
- ç”¨æˆ·éªŒæ”¶æµ‹è¯•é€šè¿‡
- ç”Ÿäº§ç¯å¢ƒç¨³å®šè¿è¡Œè‡³å°‘1å‘¨

**ä»»åŠ¡**ï¼š
1. åˆ é™¤train_modelç›®å½•ï¼ˆæ»¡è¶³å‰ç½®æ¡ä»¶åï¼‰
2. æ›´æ–°æ–‡æ¡£ï¼ˆCLAUDE.mdï¼‰
3. å‘å¸ƒå˜æ›´æ—¥å¿—
4. åˆå¹¶featureåˆ†æ”¯åˆ°main
5. åˆ›å»ºå‘å¸ƒæ ‡ç­¾v2.0.0-train-ref

**æ€»è®¡**ï¼š22å‘¨

## Open Questions

1. **æ˜¯å¦éœ€è¦ä¿ç•™train_modelçš„æ€§èƒ½åˆ†ææ¨¡å—**ï¼Ÿ
   - **å†³ç­–**ï¼šæš‚ä¸å®ç°ï¼Œä½œä¸ºå¯é€‰åŠŸèƒ½åç»­æ·»åŠ 

2. **æ˜¯å¦éœ€è¦æ”¯æŒå¹¶è¡Œè®­ç»ƒ**ï¼Ÿ
   - **å†³ç­–**ï¼šä¿ç•™ä¸²è¡Œå®ç°ï¼Œæ€§èƒ½å¯æ¥å—

3. **æµ‹è¯•è¦†ç›–ç‡æœ€ä½æ ‡å‡†**ï¼Ÿ
   - **å†³ç­–**ï¼šæ ¸å¿ƒç®—æ³•å±‚ > 90%ï¼Œå…¶ä»–å±‚ > 80%
